{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Go Emotions with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy torch nltk datasets transformers scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure necessary resources are available\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean, normalize, tokenize, remove stopwords, and lemmatize text.\"\"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove emails\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    \n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    \"\"\"Extract additional features from text\"\"\"\n",
    "    features = {}\n",
    "    original_text = text\n",
    "    \n",
    "    features['text_length'] = len(text)\n",
    "    features['word_count'] = len(text.split())\n",
    "    features['has_question'] = 1 if '?' in original_text else 0\n",
    "    features['has_exclamation'] = 1 if '!' in original_text else 0\n",
    "    features['has_emoticon'] = 1 if any(emoticon in original_text.lower() for emoticon in [':)', ':(', ':D', ';)', ':P', 'XD']) else 0\n",
    "    \n",
    "    # All caps words ratio (potential indicator of intensity)\n",
    "    words = text.split()\n",
    "    if words:\n",
    "        features['caps_ratio'] = sum(1 for word in words if word.isupper()) / len(words)\n",
    "    else:\n",
    "        features['caps_ratio'] = 0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 43410\n",
      "Validation examples: 5426\n",
      "Test examples: 5427\n",
      "Columns: Index(['text', 'labels', 'id'], dtype='object')\n",
      "Number of emotion labels: 28\n",
      "Emotion labels: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading the dataset\n",
    "data = load_dataset('go_emotions')\n",
    "df_train = pd.DataFrame(data[\"train\"])\n",
    "df_val = pd.DataFrame(data[\"validation\"])\n",
    "df_test = pd.DataFrame(data[\"test\"])\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"Training examples: {len(df_train)}\")\n",
    "print(f\"Validation examples: {len(df_val)}\")\n",
    "print(f\"Test examples: {len(df_test)}\")\n",
    "\n",
    "# Check the columns to understand what we're working with\n",
    "print(f\"Columns: {df_train.columns}\")\n",
    "\n",
    "# Get list of emotion labels\n",
    "emotion_labels = data['train'].features['labels'].feature.names\n",
    "num_labels = len(emotion_labels)\n",
    "print(f\"Number of emotion labels: {num_labels}\")\n",
    "print(f\"Emotion labels: {emotion_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text data...\n",
      "Extracting text features...\n",
      "\n",
      "Sample data with features:\n",
      "                                                text  \\\n",
      "0  My favourite food is anything I didn't have to...   \n",
      "1  Now if he does off himself, everyone will thin...   \n",
      "2                     WHY THE FUCK IS BAYLESS ISOING   \n",
      "3                        To make her feel threatened   \n",
      "4                             Dirty Southern Wankers   \n",
      "\n",
      "                                        cleaned_text  text_length  word_count  \\\n",
      "0                 favourite food anything didnt cook         59.0        11.0   \n",
      "1  everyone think he laugh screwing people instea...        112.0        20.0   \n",
      "2                                fuck bayless isoing         30.0         6.0   \n",
      "3                               make feel threatened         27.0         5.0   \n",
      "4                              dirty southern wanker         22.0         3.0   \n",
      "\n",
      "   has_question  has_exclamation  caps_ratio  \n",
      "0           0.0              0.0    0.090909  \n",
      "1           0.0              0.0    0.000000  \n",
      "2           0.0              0.0    1.000000  \n",
      "3           0.0              0.0    0.000000  \n",
      "4           0.0              0.0    0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Add preprocessed text columns\n",
    "print(\"Preprocessing text data...\")\n",
    "df_train['cleaned_text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['cleaned_text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['cleaned_text'] = df_test['text'].apply(preprocess_text)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting text features...\")\n",
    "train_features = df_train['text'].apply(extract_features).apply(pd.Series)\n",
    "val_features = df_val['text'].apply(extract_features).apply(pd.Series)\n",
    "test_features = df_test['text'].apply(extract_features).apply(pd.Series)\n",
    "\n",
    "# Add features to dataframes\n",
    "for feature in train_features.columns:\n",
    "    df_train[feature] = train_features[feature]\n",
    "    df_val[feature] = val_features[feature]\n",
    "    df_test[feature] = test_features[feature]\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample data with features:\")\n",
    "print(df_train[['text', 'cleaned_text', 'text_length', 'word_count', 'has_question', 'has_exclamation', 'caps_ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Add cleaned text to the dataset\n",
    "data[\"train\"] = data[\"train\"].add_column(\"cleaned_text\", df_train[\"cleaned_text\"].tolist())\n",
    "data[\"validation\"] = data[\"validation\"].add_column(\"cleaned_text\", df_val[\"cleaned_text\"].tolist())\n",
    "data[\"test\"] = data[\"test\"].add_column(\"cleaned_text\", df_test[\"cleaned_text\"].tolist())\n",
    "\n",
    "# Create a custom dataset class that incorporates text features\n",
    "class GoEmotionsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, features):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        \n",
    "        # Add text features\n",
    "        for feature_name, feature_values in self.features.items():\n",
    "            item[feature_name] = torch.tensor(feature_values[idx], dtype=torch.float)\n",
    "        \n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5713f64ad44aaa8fb85ac41ec0e70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_name = \"distilbert-base-uncased\"  # A good balance of performance and speed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"cleaned_text\"] if \"cleaned_text\" in examples else examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Prepare datasets for training\n",
    "train_dataset = data[\"train\"].map(tokenize_function, batched=True)\n",
    "val_dataset = data[\"validation\"].map(tokenize_function, batched=True)\n",
    "test_dataset = data[\"test\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric features from dataframes\n",
    "train_numeric_features = {\n",
    "    'text_length': df_train['text_length'].values,\n",
    "    'word_count': df_train['word_count'].values,\n",
    "    'has_question': df_train['has_question'].values,\n",
    "    'has_exclamation': df_train['has_exclamation'].values,\n",
    "    'has_emoticon': df_train['has_emoticon'].values,\n",
    "    'caps_ratio': df_train['caps_ratio'].values\n",
    "}\n",
    "\n",
    "val_numeric_features = {\n",
    "    'text_length': df_val['text_length'].values,\n",
    "    'word_count': df_val['word_count'].values,\n",
    "    'has_question': df_val['has_question'].values,\n",
    "    'has_exclamation': df_val['has_exclamation'].values,\n",
    "    'has_emoticon': df_val['has_emoticon'].values,\n",
    "    'caps_ratio': df_val['caps_ratio'].values\n",
    "}\n",
    "\n",
    "test_numeric_features = {\n",
    "    'text_length': df_test['text_length'].values,\n",
    "    'word_count': df_test['word_count'].values,\n",
    "    'has_question': df_test['has_question'].values,\n",
    "    'has_exclamation': df_test['has_exclamation'].values,\n",
    "    'has_emoticon': df_test['has_emoticon'].values,\n",
    "    'caps_ratio': df_test['caps_ratio'].values\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf16ea804774aa6938035336815763b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert labels to the expected format for multi-label classification\n",
    "def process_labels(examples):\n",
    "    # Convert label indices to multi-hot encoding\n",
    "    labels = np.zeros((len(examples[\"labels\"]), num_labels))\n",
    "    for i, label_list in enumerate(examples[\"labels\"]):\n",
    "        labels[i, label_list] = 1\n",
    "    return {\"labels\": labels.tolist()}\n",
    "\n",
    "train_dataset = train_dataset.map(process_labels, batched=True)\n",
    "val_dataset = val_dataset.map(process_labels, batched=True)\n",
    "test_dataset = test_dataset.map(process_labels, batched=True)\n",
    "\n",
    "# Create custom datasets with features\n",
    "# Get processed labels\n",
    "train_labels = np.array(train_dataset[\"labels\"])\n",
    "val_labels = np.array(val_dataset[\"labels\"])\n",
    "test_labels = np.array(test_dataset[\"labels\"])\n",
    "\n",
    "# Remove labels from encodings\n",
    "train_encodings = {k: v for k, v in train_dataset.to_dict().items() if k != \"labels\"}\n",
    "val_encodings = {k: v for k, v in val_dataset.to_dict().items() if k != \"labels\"}\n",
    "test_encodings = {k: v for k, v in test_dataset.to_dict().items() if k != \"labels\"}\n",
    "\n",
    "# Create custom datasets\n",
    "custom_train_dataset = GoEmotionsDataset(train_encodings, train_labels, train_numeric_features)\n",
    "custom_val_dataset = GoEmotionsDataset(val_encodings, val_labels, val_numeric_features)\n",
    "custom_test_dataset = GoEmotionsDataset(test_encodings, test_labels, test_numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom model that incorporates text features\n",
    "from transformers import DistilBertPreTrainedModel, DistilBertModel\n",
    "from torch import nn\n",
    "\n",
    "class EmotionClassifier(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        # Number of additional features\n",
    "        self.num_features = 6  # text_length, word_count, etc.\n",
    "        \n",
    "        # Add a feature extractor network\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(self.num_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Combine BERT embeddings with our features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size + 32, config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(config.hidden_size, config.num_labels)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.post_init()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, head_mask=None, \n",
    "                inputs_embeds=None, labels=None, output_attentions=None, \n",
    "                output_hidden_states=None, return_dict=None, **kwargs):\n",
    "        \n",
    "        # Get text features from kwargs\n",
    "        text_features = []\n",
    "        for feature_name in ['text_length', 'word_count', 'has_question', \n",
    "                            'has_exclamation', 'has_emoticon', 'caps_ratio']:\n",
    "            if feature_name in kwargs:\n",
    "                text_features.append(kwargs[feature_name].unsqueeze(1))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        if text_features:\n",
    "            text_features = torch.cat(text_features, dim=1)\n",
    "        else:\n",
    "            # If no features provided, use zeros as fallback\n",
    "            text_features = torch.zeros(input_ids.shape[0], self.num_features, device=input_ids.device)\n",
    "        \n",
    "        # Get BERT embeddings\n",
    "        outputs = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "        \n",
    "        # Get the CLS token embedding\n",
    "        bert_output = outputs[0][:, 0]  # CLS token\n",
    "        \n",
    "        # Process the features\n",
    "        feature_output = self.feature_extractor(text_features)\n",
    "        \n",
    "        # Concatenate BERT output with features\n",
    "        combined = torch.cat([bert_output, feature_output], dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        # loss = None\n",
    "        # if labels is not None:\n",
    "        #     loss_fct = nn.BCEWithLogitsLoss()\n",
    "        #     loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "        #                    labels.float().view(-1, self.num_labels))\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Use class weights if available\n",
    "            if hasattr(self, 'pos_weights'):\n",
    "                loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights)\n",
    "            else:\n",
    "                loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                        labels.float().view(-1, self.num_labels))\n",
    "\n",
    "        return (loss, logits) if loss is not None else logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EmotionClassifier were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.0.bias', 'classifier.0.weight', 'classifier.3.bias', 'classifier.3.weight', 'feature_extractor.0.bias', 'feature_extractor.0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on GPU\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained DistilBERT config and modify it\n",
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Initialize our custom model\n",
    "model = EmotionClassifier.from_pretrained(\n",
    "    model_name,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Check if GPU is available and move model to GPU\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "    print(\"Model loaded on GPU\")\n",
    "else:\n",
    "    print(\"Model loaded on CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights based on label distribution\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Reshape labels for weight calculation (train_labels is multi-hot encoded)\n",
    "flat_labels = np.where(train_labels == 1)[1]  # Get indices of positive labels\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', \n",
    "                                    classes=np.unique(flat_labels), \n",
    "                                    y=flat_labels)\n",
    "                                    \n",
    "# Convert to tensor and move to appropriate device\n",
    "pos_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "if torch.cuda.is_available():\n",
    "    pos_weights = pos_weights.to('cuda')\n",
    "\n",
    "# Pass these weights to the model\n",
    "model.pos_weights = pos_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\anaconda3\\envs\\mindscribe\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(pred):\n",
    "    predictions = (pred.predictions > 0).astype(int)\n",
    "    labels = pred.label_ids\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels.flatten(), predictions.flatten())\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    precision = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# # Set up training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     push_to_hub=False,\n",
    "#     fp16=torch.cuda.is_available(),  # Enable mixed precision if GPU available\n",
    "# )\n",
    "\n",
    "\n",
    "# Set up training arguments with improvements\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,  # Slightly lower learning rate\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,  # Increase training epochs\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",  # Evaluate more frequently\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",  # Optimize for F1 score\n",
    "    greater_is_better=True,\n",
    "    push_to_hub=False,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=100,\n",
    "    warmup_steps=500,  # Add warmup steps\n",
    "    lr_scheduler_type=\"linear\",  # Use linear scheduler\n",
    "    gradient_accumulation_steps=2,  # Effectively doubles batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malbert-negoro89\u001b[0m (\u001b[33malbert-negoro89-arizona-state-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\MindScribe\\NewMLAlgo\\transformers\\wandb\\run-20250226_170354-pp53j1g4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/albert-negoro89-arizona-state-university/huggingface/runs/pp53j1g4' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/albert-negoro89-arizona-state-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/albert-negoro89-arizona-state-university/huggingface' target=\"_blank\">https://wandb.ai/albert-negoro89-arizona-state-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/albert-negoro89-arizona-state-university/huggingface/runs/pp53j1g4' target=\"_blank\">https://wandb.ai/albert-negoro89-arizona-state-university/huggingface/runs/pp53j1g4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07e585919184608a4e91cda5dd61fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6703, 'grad_norm': 1.4818263053894043, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 0.4467, 'grad_norm': 1.4410593509674072, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 0.2633, 'grad_norm': 0.895915687084198, 'learning_rate': 1.2e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1856, 'grad_norm': 0.6379570364952087, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1727, 'grad_norm': 0.451177716255188, 'learning_rate': 2e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6e05f8580a4516b74428d711c49f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.176142156124115, 'eval_accuracy': 0.9580064240956242, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 3.6661, 'eval_samples_per_second': 1480.056, 'eval_steps_per_second': 92.742, 'epoch': 0.37}\n",
      "{'loss': 0.1736, 'grad_norm': 1.2803378105163574, 'learning_rate': 1.984697781178271e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1816, 'grad_norm': 0.5326987504959106, 'learning_rate': 1.969395562356542e-05, 'epoch': 0.52}\n",
      "{'loss': 0.1839, 'grad_norm': 0.5067772269248962, 'learning_rate': 1.9540933435348126e-05, 'epoch': 0.59}\n",
      "{'loss': 0.1719, 'grad_norm': 0.4756167531013489, 'learning_rate': 1.9387911247130835e-05, 'epoch': 0.66}\n",
      "{'loss': 0.1571, 'grad_norm': 0.4957443177700043, 'learning_rate': 1.9234889058913545e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698ad2d3defa45eaa3a31b293d7cbc3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1535516381263733, 'eval_accuracy': 0.9581709757253436, 'eval_f1': 0.0077014865001516835, 'eval_precision': 0.006860519583468454, 'eval_recall': 0.00877742946708464, 'eval_runtime': 3.5667, 'eval_samples_per_second': 1521.305, 'eval_steps_per_second': 95.327, 'epoch': 0.74}\n",
      "{'loss': 0.1516, 'grad_norm': 0.5781682729721069, 'learning_rate': 1.9081866870696254e-05, 'epoch': 0.81}\n",
      "{'loss': 0.1484, 'grad_norm': 0.5314978957176208, 'learning_rate': 1.8928844682478963e-05, 'epoch': 0.88}\n",
      "{'loss': 0.1395, 'grad_norm': 1.2173354625701904, 'learning_rate': 1.877582249426167e-05, 'epoch': 0.96}\n",
      "{'loss': 0.1332, 'grad_norm': 0.559838056564331, 'learning_rate': 1.862280030604438e-05, 'epoch': 1.03}\n",
      "{'loss': 0.1286, 'grad_norm': 1.4240052700042725, 'learning_rate': 1.8469778117827088e-05, 'epoch': 1.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7688a63e60e6481fa2e8ea53d631f1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1207302138209343, 'eval_accuracy': 0.9625151387499342, 'eval_f1': 0.17005875448726687, 'eval_precision': 0.2504385464155222, 'eval_recall': 0.1487460815047022, 'eval_runtime': 3.5621, 'eval_samples_per_second': 1523.268, 'eval_steps_per_second': 95.45, 'epoch': 1.11}\n",
      "{'loss': 0.1232, 'grad_norm': 1.436185359954834, 'learning_rate': 1.8316755929609794e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1242, 'grad_norm': 0.5424305200576782, 'learning_rate': 1.8163733741392503e-05, 'epoch': 1.25}\n",
      "{'loss': 0.114, 'grad_norm': 0.6921884417533875, 'learning_rate': 1.8010711553175212e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1152, 'grad_norm': 0.5870735049247742, 'learning_rate': 1.7857689364957918e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1194, 'grad_norm': 0.4806309640407562, 'learning_rate': 1.7704667176740627e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2507ecda12584d098f069c8c81a1e12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11288198828697205, 'eval_accuracy': 0.9631667632036228, 'eval_f1': 0.2262408586707799, 'eval_precision': 0.31782319477191967, 'eval_recall': 0.19655172413793104, 'eval_runtime': 3.1602, 'eval_samples_per_second': 1716.959, 'eval_steps_per_second': 107.587, 'epoch': 1.47}\n",
      "{'loss': 0.1162, 'grad_norm': 0.7124719619750977, 'learning_rate': 1.7551644988523337e-05, 'epoch': 1.55}\n",
      "{'loss': 0.111, 'grad_norm': 0.7519200444221497, 'learning_rate': 1.7398622800306046e-05, 'epoch': 1.62}\n",
      "{'loss': 0.112, 'grad_norm': 0.7556813955307007, 'learning_rate': 1.7245600612088755e-05, 'epoch': 1.69}\n",
      "{'loss': 0.1104, 'grad_norm': 0.7455730438232422, 'learning_rate': 1.709257842387146e-05, 'epoch': 1.77}\n",
      "{'loss': 0.1071, 'grad_norm': 0.7523863315582275, 'learning_rate': 1.693955623565417e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8564abb80bf64430a7b4c63f8031b540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10747367143630981, 'eval_accuracy': 0.9635880153757043, 'eval_f1': 0.2592986780553055, 'eval_precision': 0.37565926803576194, 'eval_recall': 0.22884012539184953, 'eval_runtime': 3.0531, 'eval_samples_per_second': 1777.231, 'eval_steps_per_second': 111.364, 'epoch': 1.84}\n",
      "{'loss': 0.107, 'grad_norm': 0.6564183235168457, 'learning_rate': 1.678653404743688e-05, 'epoch': 1.92}\n",
      "{'loss': 0.1146, 'grad_norm': 0.5673279166221619, 'learning_rate': 1.663351185921959e-05, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 3.1949009895324707, 'learning_rate': 1.64804896710023e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1011, 'grad_norm': 0.6810345649719238, 'learning_rate': 1.6327467482785004e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1025, 'grad_norm': 0.7549296021461487, 'learning_rate': 1.6174445294567714e-05, 'epoch': 2.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad664181f4c14973ac5bdc2b54ec7f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10755860060453415, 'eval_accuracy': 0.9638381338528776, 'eval_f1': 0.27454460043395656, 'eval_precision': 0.37438415621530563, 'eval_recall': 0.2421630094043887, 'eval_runtime': 3.3345, 'eval_samples_per_second': 1627.244, 'eval_steps_per_second': 101.965, 'epoch': 2.21}\n",
      "{'loss': 0.1039, 'grad_norm': 0.8730422854423523, 'learning_rate': 1.6021423106350423e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0993, 'grad_norm': 0.5700458884239197, 'learning_rate': 1.5868400918133132e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0989, 'grad_norm': 3.8379528522491455, 'learning_rate': 1.571537872991584e-05, 'epoch': 2.43}\n",
      "{'loss': 0.1002, 'grad_norm': 0.7672767639160156, 'learning_rate': 1.5562356541698547e-05, 'epoch': 2.51}\n",
      "{'loss': 0.1025, 'grad_norm': 1.6742726564407349, 'learning_rate': 1.5409334353481257e-05, 'epoch': 2.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5a90bcb9d04ebfb6b219541cf05042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10461688041687012, 'eval_accuracy': 0.9631338528776789, 'eval_f1': 0.28210003942312384, 'eval_precision': 0.458256100918088, 'eval_recall': 0.2584639498432602, 'eval_runtime': 3.0527, 'eval_samples_per_second': 1777.457, 'eval_steps_per_second': 111.378, 'epoch': 2.58}\n",
      "{'loss': 0.0968, 'grad_norm': 0.8232335448265076, 'learning_rate': 1.5256312165263964e-05, 'epoch': 2.65}\n",
      "{'loss': 0.1011, 'grad_norm': 2.3566648960113525, 'learning_rate': 1.5103289977046673e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0956, 'grad_norm': 0.832960844039917, 'learning_rate': 1.4950267788829383e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0914, 'grad_norm': 0.8221614360809326, 'learning_rate': 1.4797245600612089e-05, 'epoch': 2.87}\n",
      "{'loss': 0.0947, 'grad_norm': 0.5743135213851929, 'learning_rate': 1.4644223412394798e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885e8c8686064f5688799050fbb2055c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10491683334112167, 'eval_accuracy': 0.9640553420041073, 'eval_f1': 0.2902804350891198, 'eval_precision': 0.46553575430258715, 'eval_recall': 0.2573667711598746, 'eval_runtime': 3.1469, 'eval_samples_per_second': 1724.216, 'eval_steps_per_second': 108.042, 'epoch': 2.95}\n",
      "{'loss': 0.0946, 'grad_norm': 0.8363548517227173, 'learning_rate': 1.449273144605968e-05, 'epoch': 3.02}\n",
      "{'loss': 0.0867, 'grad_norm': 1.017137050628662, 'learning_rate': 1.433970925784239e-05, 'epoch': 3.1}\n",
      "{'loss': 0.088, 'grad_norm': 1.0113731622695923, 'learning_rate': 1.4186687069625096e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0886, 'grad_norm': 2.0993387699127197, 'learning_rate': 1.4033664881407805e-05, 'epoch': 3.24}\n",
      "{'loss': 0.086, 'grad_norm': 0.6556255221366882, 'learning_rate': 1.3880642693190514e-05, 'epoch': 3.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f835adb6800a44f1bd4bf3d375afe9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10529347509145737, 'eval_accuracy': 0.9640092675477858, 'eval_f1': 0.30512515208298435, 'eval_precision': 0.5168086342442652, 'eval_recall': 0.2736677115987461, 'eval_runtime': 3.2615, 'eval_samples_per_second': 1663.646, 'eval_steps_per_second': 104.246, 'epoch': 3.32}\n",
      "{'loss': 0.0884, 'grad_norm': 0.6325908303260803, 'learning_rate': 1.3727620504973222e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0857, 'grad_norm': 0.8645972609519958, 'learning_rate': 1.3576128538638102e-05, 'epoch': 3.46}\n",
      "{'loss': 0.0895, 'grad_norm': 1.9085578918457031, 'learning_rate': 1.3423106350420812e-05, 'epoch': 3.54}\n",
      "{'loss': 0.0864, 'grad_norm': 1.0664838552474976, 'learning_rate': 1.3270084162203521e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0897, 'grad_norm': 0.9331812858581543, 'learning_rate': 1.3117061973986229e-05, 'epoch': 3.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefd458fc6a84a4a951cbcc7aa15b579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10429470986127853, 'eval_accuracy': 0.9636275077668369, 'eval_f1': 0.3085846409611024, 'eval_precision': 0.7449155957468633, 'eval_recall': 0.2818181818181818, 'eval_runtime': 3.4146, 'eval_samples_per_second': 1589.077, 'eval_steps_per_second': 99.574, 'epoch': 3.68}\n",
      "{'loss': 0.0884, 'grad_norm': 0.6646069288253784, 'learning_rate': 1.2964039785768938e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0902, 'grad_norm': 1.5386028289794922, 'learning_rate': 1.2811017597551647e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0864, 'grad_norm': 0.8018712401390076, 'learning_rate': 1.2657995409334353e-05, 'epoch': 3.91}\n",
      "{'loss': 0.0889, 'grad_norm': 1.051065444946289, 'learning_rate': 1.2504973221117062e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0789, 'grad_norm': 0.7616689205169678, 'learning_rate': 1.2351951032899772e-05, 'epoch': 4.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939de1c924de4c8b9def7da666ea7291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1061759889125824, 'eval_accuracy': 0.9636933284187247, 'eval_f1': 0.3172998005003649, 'eval_precision': 0.754852035703854, 'eval_recall': 0.2874608150470219, 'eval_runtime': 3.1828, 'eval_samples_per_second': 1704.801, 'eval_steps_per_second': 106.825, 'epoch': 4.05}\n",
      "{'loss': 0.0782, 'grad_norm': 0.7168601155281067, 'learning_rate': 1.2198928844682481e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0766, 'grad_norm': 0.8667905926704407, 'learning_rate': 1.204590665646519e-05, 'epoch': 4.2}\n",
      "{'loss': 0.08, 'grad_norm': 1.0344047546386719, 'learning_rate': 1.1892884468247896e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0775, 'grad_norm': 0.7376607060432434, 'learning_rate': 1.1739862280030605e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0787, 'grad_norm': 0.7732806205749512, 'learning_rate': 1.1586840091813315e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ca2522381f4fc2b2d374c6c7f3ae8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10806291550397873, 'eval_accuracy': 0.9637328208098573, 'eval_f1': 0.32210581508302616, 'eval_precision': 0.7414075524171891, 'eval_recall': 0.29169278996865206, 'eval_runtime': 3.069, 'eval_samples_per_second': 1768.022, 'eval_steps_per_second': 110.787, 'epoch': 4.42}\n",
      "{'loss': 0.0775, 'grad_norm': 3.6777687072753906, 'learning_rate': 1.1433817903596022e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0795, 'grad_norm': 0.731162428855896, 'learning_rate': 1.1280795715378732e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0782, 'grad_norm': 1.0120034217834473, 'learning_rate': 1.112777352716144e-05, 'epoch': 4.64}\n",
      "{'loss': 0.0805, 'grad_norm': 2.688056707382202, 'learning_rate': 1.0974751338944147e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0752, 'grad_norm': 0.7908505797386169, 'learning_rate': 1.0821729150726856e-05, 'epoch': 4.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2df92d131f4af4a22efe68a9911c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11027836799621582, 'eval_accuracy': 0.9642330577642041, 'eval_f1': 0.31604541860635393, 'eval_precision': 0.744119464744957, 'eval_recall': 0.2753918495297806, 'eval_runtime': 3.0016, 'eval_samples_per_second': 1807.696, 'eval_steps_per_second': 113.272, 'epoch': 4.79}\n",
      "{'loss': 0.0774, 'grad_norm': 1.2842286825180054, 'learning_rate': 1.0668706962509565e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0797, 'grad_norm': 1.2963978052139282, 'learning_rate': 1.0515684774292275e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0768, 'grad_norm': 0.8828572034835815, 'learning_rate': 1.036266258607498e-05, 'epoch': 5.01}\n",
      "{'loss': 0.0731, 'grad_norm': 0.8276371359825134, 'learning_rate': 1.020964039785769e-05, 'epoch': 5.08}\n",
      "{'loss': 0.0709, 'grad_norm': 0.9744724631309509, 'learning_rate': 1.0056618209640399e-05, 'epoch': 5.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5079eb897f24bbca7726b4ab2cd6d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1106201782822609, 'eval_accuracy': 0.9637394028750461, 'eval_f1': 0.32445732912591935, 'eval_precision': 0.7199697956590252, 'eval_recall': 0.285423197492163, 'eval_runtime': 3.0601, 'eval_samples_per_second': 1773.165, 'eval_steps_per_second': 111.109, 'epoch': 5.16}\n",
      "{'loss': 0.0678, 'grad_norm': 0.8326922655105591, 'learning_rate': 9.903596021423107e-06, 'epoch': 5.23}\n",
      "{'loss': 0.069, 'grad_norm': 0.8306703567504883, 'learning_rate': 9.750573833205816e-06, 'epoch': 5.31}\n",
      "{'loss': 0.0712, 'grad_norm': 0.7732207179069519, 'learning_rate': 9.597551644988524e-06, 'epoch': 5.38}\n",
      "{'loss': 0.0696, 'grad_norm': 1.0576950311660767, 'learning_rate': 9.444529456771233e-06, 'epoch': 5.45}\n",
      "{'loss': 0.0703, 'grad_norm': 0.6791108846664429, 'learning_rate': 9.29150726855394e-06, 'epoch': 5.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba70086f680b4e6db04451e5c9a74a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11293172836303711, 'eval_accuracy': 0.9633247327681533, 'eval_f1': 0.3259080257516103, 'eval_precision': 0.6605392249239089, 'eval_recall': 0.29169278996865206, 'eval_runtime': 3.023, 'eval_samples_per_second': 1794.886, 'eval_steps_per_second': 112.47, 'epoch': 5.53}\n",
      "{'loss': 0.0719, 'grad_norm': 0.9457306861877441, 'learning_rate': 9.140015302218823e-06, 'epoch': 5.6}\n",
      "{'loss': 0.0691, 'grad_norm': 0.7998746633529663, 'learning_rate': 8.98699311400153e-06, 'epoch': 5.67}\n",
      "{'loss': 0.0681, 'grad_norm': 0.8884339928627014, 'learning_rate': 8.83397092578424e-06, 'epoch': 5.75}\n",
      "{'loss': 0.0708, 'grad_norm': 0.9116162061691284, 'learning_rate': 8.680948737566947e-06, 'epoch': 5.82}\n",
      "{'loss': 0.0667, 'grad_norm': 0.9349080920219421, 'learning_rate': 8.527926549349657e-06, 'epoch': 5.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10c1ccf087d4944baf8030d27d961aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11200952529907227, 'eval_accuracy': 0.9632523300510768, 'eval_f1': 0.3296824235123006, 'eval_precision': 0.6768366796868893, 'eval_recall': 0.29968652037617555, 'eval_runtime': 3.1276, 'eval_samples_per_second': 1734.897, 'eval_steps_per_second': 108.711, 'epoch': 5.9}\n",
      "{'loss': 0.0716, 'grad_norm': 1.0005426406860352, 'learning_rate': 8.376434583014537e-06, 'epoch': 5.97}\n",
      "{'loss': 0.0627, 'grad_norm': 0.9553356766700745, 'learning_rate': 8.223412394797247e-06, 'epoch': 6.04}\n",
      "{'loss': 0.0621, 'grad_norm': 0.8453904390335083, 'learning_rate': 8.070390206579954e-06, 'epoch': 6.12}\n",
      "{'loss': 0.0621, 'grad_norm': 1.1616870164871216, 'learning_rate': 7.917368018362664e-06, 'epoch': 6.19}\n",
      "{'loss': 0.0635, 'grad_norm': 0.8313819766044617, 'learning_rate': 7.764345830145373e-06, 'epoch': 6.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fdc0b59f9b41aeb5aefd6dcbbc2872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11636032164096832, 'eval_accuracy': 0.9636735822231584, 'eval_f1': 0.34634791856164254, 'eval_precision': 0.6691899065839136, 'eval_recall': 0.30595611285266455, 'eval_runtime': 3.0579, 'eval_samples_per_second': 1774.431, 'eval_steps_per_second': 111.188, 'epoch': 6.26}\n",
      "{'loss': 0.0637, 'grad_norm': 0.8224002718925476, 'learning_rate': 7.61132364192808e-06, 'epoch': 6.34}\n",
      "{'loss': 0.0652, 'grad_norm': 1.4366868734359741, 'learning_rate': 7.458301453710789e-06, 'epoch': 6.41}\n",
      "{'loss': 0.0635, 'grad_norm': 1.3260701894760132, 'learning_rate': 7.3052792654934965e-06, 'epoch': 6.48}\n",
      "{'loss': 0.0629, 'grad_norm': 0.8972442746162415, 'learning_rate': 7.152257077276206e-06, 'epoch': 6.56}\n",
      "{'loss': 0.0627, 'grad_norm': 0.9457471370697021, 'learning_rate': 6.999234889058914e-06, 'epoch': 6.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ebf76082934f398fbb6093ea1ad6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11768282204866409, 'eval_accuracy': 0.963917118635143, 'eval_f1': 0.35009827047246556, 'eval_precision': 0.6754975441322976, 'eval_recall': 0.30689655172413793, 'eval_runtime': 3.0966, 'eval_samples_per_second': 1752.231, 'eval_steps_per_second': 109.797, 'epoch': 6.63}\n",
      "{'loss': 0.0635, 'grad_norm': 0.9568567276000977, 'learning_rate': 6.846212700841623e-06, 'epoch': 6.71}\n",
      "{'loss': 0.0652, 'grad_norm': 1.254683017730713, 'learning_rate': 6.693190512624331e-06, 'epoch': 6.78}\n",
      "{'loss': 0.0634, 'grad_norm': 1.0171293020248413, 'learning_rate': 6.540168324407039e-06, 'epoch': 6.85}\n",
      "{'loss': 0.0664, 'grad_norm': 0.6855462193489075, 'learning_rate': 6.387146136189748e-06, 'epoch': 6.93}\n",
      "{'loss': 0.0599, 'grad_norm': 1.1485294103622437, 'learning_rate': 6.234123947972457e-06, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79101019a41b42af958fa721d505687c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11977747082710266, 'eval_accuracy': 0.9635748512453267, 'eval_f1': 0.3492267822393212, 'eval_precision': 0.6692085544106906, 'eval_recall': 0.30626959247648905, 'eval_runtime': 3.0858, 'eval_samples_per_second': 1758.357, 'eval_steps_per_second': 110.181, 'epoch': 7.0}\n",
      "{'loss': 0.0582, 'grad_norm': 0.8502678275108337, 'learning_rate': 6.081101759755165e-06, 'epoch': 7.07}\n",
      "{'loss': 0.0585, 'grad_norm': 3.2378292083740234, 'learning_rate': 5.928079571537873e-06, 'epoch': 7.15}\n",
      "{'loss': 0.0583, 'grad_norm': 0.898062527179718, 'learning_rate': 5.775057383320582e-06, 'epoch': 7.22}\n",
      "{'loss': 0.0581, 'grad_norm': 1.072053074836731, 'learning_rate': 5.62203519510329e-06, 'epoch': 7.3}\n",
      "{'loss': 0.0599, 'grad_norm': 4.647213935852051, 'learning_rate': 5.4690130068859995e-06, 'epoch': 7.37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939e012b770a4f82894560a21f1c61aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1193893775343895, 'eval_accuracy': 0.9629232267916381, 'eval_f1': 0.3578844579199506, 'eval_precision': 0.6520839224277236, 'eval_recall': 0.31880877742946706, 'eval_runtime': 3.1643, 'eval_samples_per_second': 1714.734, 'eval_steps_per_second': 107.447, 'epoch': 7.37}\n",
      "{'loss': 0.0577, 'grad_norm': 0.8279275894165039, 'learning_rate': 5.315990818668707e-06, 'epoch': 7.44}\n",
      "{'loss': 0.0568, 'grad_norm': 0.8180505037307739, 'learning_rate': 5.162968630451416e-06, 'epoch': 7.52}\n",
      "{'loss': 0.0593, 'grad_norm': 1.1571886539459229, 'learning_rate': 5.009946442234125e-06, 'epoch': 7.59}\n",
      "{'loss': 0.0575, 'grad_norm': 1.0878573656082153, 'learning_rate': 4.856924254016832e-06, 'epoch': 7.66}\n",
      "{'loss': 0.0587, 'grad_norm': 0.843271791934967, 'learning_rate': 4.703902065799542e-06, 'epoch': 7.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f9abad87404bea80b89033d0581107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12098520249128342, 'eval_accuracy': 0.9631535990732453, 'eval_f1': 0.3626325683616767, 'eval_precision': 0.6573126757543235, 'eval_recall': 0.32147335423197493, 'eval_runtime': 3.2187, 'eval_samples_per_second': 1685.8, 'eval_steps_per_second': 105.634, 'epoch': 7.74}\n",
      "{'loss': 0.0562, 'grad_norm': 1.0744048357009888, 'learning_rate': 4.55087987758225e-06, 'epoch': 7.81}\n",
      "{'loss': 0.057, 'grad_norm': 1.2183935642242432, 'learning_rate': 4.3978576893649585e-06, 'epoch': 7.89}\n",
      "{'loss': 0.0578, 'grad_norm': 1.472259283065796, 'learning_rate': 4.244835501147667e-06, 'epoch': 7.96}\n",
      "{'loss': 0.0569, 'grad_norm': 0.8545963168144226, 'learning_rate': 4.091813312930375e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0525, 'grad_norm': 0.6764536499977112, 'learning_rate': 3.938791124713084e-06, 'epoch': 8.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c786e51d4e294736a0b550643c8704b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1238512396812439, 'eval_accuracy': 0.9632589121162656, 'eval_f1': 0.3673380775657221, 'eval_precision': 0.6462127204600816, 'eval_recall': 0.3221003134796238, 'eval_runtime': 3.0772, 'eval_samples_per_second': 1763.315, 'eval_steps_per_second': 110.492, 'epoch': 8.11}\n",
      "{'loss': 0.0555, 'grad_norm': 1.091623306274414, 'learning_rate': 3.7857689364957923e-06, 'epoch': 8.18}\n",
      "{'loss': 0.0528, 'grad_norm': 0.9153516888618469, 'learning_rate': 3.6327467482785008e-06, 'epoch': 8.25}\n",
      "{'loss': 0.0556, 'grad_norm': 1.3724726438522339, 'learning_rate': 3.4797245600612088e-06, 'epoch': 8.33}\n",
      "{'loss': 0.0535, 'grad_norm': 1.564528465270996, 'learning_rate': 3.326702371843918e-06, 'epoch': 8.4}\n",
      "{'loss': 0.0528, 'grad_norm': 1.2574080228805542, 'learning_rate': 3.173680183626626e-06, 'epoch': 8.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735051890d4b4699b1b98023e6973fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12537036836147308, 'eval_accuracy': 0.9637854773313674, 'eval_f1': 0.3737334651470462, 'eval_precision': 0.6528838405882988, 'eval_recall': 0.3236677115987461, 'eval_runtime': 3.1325, 'eval_samples_per_second': 1732.166, 'eval_steps_per_second': 108.54, 'epoch': 8.47}\n",
      "{'loss': 0.0536, 'grad_norm': 1.4430060386657715, 'learning_rate': 3.0206579954093345e-06, 'epoch': 8.55}\n",
      "{'loss': 0.0546, 'grad_norm': 1.3935166597366333, 'learning_rate': 2.867635807192043e-06, 'epoch': 8.62}\n",
      "{'loss': 0.0547, 'grad_norm': 0.840077817440033, 'learning_rate': 2.7146136189747514e-06, 'epoch': 8.7}\n",
      "{'loss': 0.0562, 'grad_norm': 1.0477360486984253, 'learning_rate': 2.5615914307574603e-06, 'epoch': 8.77}\n",
      "{'loss': 0.054, 'grad_norm': 1.077167272567749, 'learning_rate': 2.4085692425401687e-06, 'epoch': 8.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0800590c7c34966b50e695db8257a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12626788020133972, 'eval_accuracy': 0.9638315517876889, 'eval_f1': 0.37442596660949495, 'eval_precision': 0.6509328972240173, 'eval_recall': 0.32241379310344825, 'eval_runtime': 3.363, 'eval_samples_per_second': 1613.453, 'eval_steps_per_second': 101.101, 'epoch': 8.84}\n",
      "{'loss': 0.0557, 'grad_norm': 0.918236494064331, 'learning_rate': 2.2555470543228767e-06, 'epoch': 8.92}\n",
      "{'loss': 0.0556, 'grad_norm': 0.7294603586196899, 'learning_rate': 2.1025248661055856e-06, 'epoch': 8.99}\n",
      "{'loss': 0.0514, 'grad_norm': 0.9611464738845825, 'learning_rate': 1.949502677888294e-06, 'epoch': 9.06}\n",
      "{'loss': 0.0505, 'grad_norm': 0.9171906113624573, 'learning_rate': 1.7964804896710025e-06, 'epoch': 9.14}\n",
      "{'loss': 0.0523, 'grad_norm': 0.6333191394805908, 'learning_rate': 1.643458301453711e-06, 'epoch': 9.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26b8dc0c91e4fbcb7f2615700aac564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12523885071277618, 'eval_accuracy': 0.963245747985888, 'eval_f1': 0.37286978639494384, 'eval_precision': 0.6453297486434203, 'eval_recall': 0.3274294670846395, 'eval_runtime': 2.9989, 'eval_samples_per_second': 1809.33, 'eval_steps_per_second': 113.375, 'epoch': 9.21}\n",
      "{'loss': 0.0529, 'grad_norm': 1.330005407333374, 'learning_rate': 1.4904361132364196e-06, 'epoch': 9.29}\n",
      "{'loss': 0.051, 'grad_norm': 1.129470705986023, 'learning_rate': 1.3374139250191278e-06, 'epoch': 9.36}\n",
      "{'loss': 0.0525, 'grad_norm': 1.4215322732925415, 'learning_rate': 1.1843917368018365e-06, 'epoch': 9.43}\n",
      "{'loss': 0.053, 'grad_norm': 1.2234958410263062, 'learning_rate': 1.031369548584545e-06, 'epoch': 9.51}\n",
      "{'loss': 0.051, 'grad_norm': 1.0394752025604248, 'learning_rate': 8.783473603672533e-07, 'epoch': 9.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1978821a5f94c7ba87c0850efe7b7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12615908682346344, 'eval_accuracy': 0.9632589121162656, 'eval_f1': 0.37310288232502486, 'eval_precision': 0.640266833217612, 'eval_recall': 0.325705329153605, 'eval_runtime': 3.2342, 'eval_samples_per_second': 1677.71, 'eval_steps_per_second': 105.127, 'epoch': 9.58}\n",
      "{'loss': 0.0516, 'grad_norm': 1.1355153322219849, 'learning_rate': 7.253251721499618e-07, 'epoch': 9.65}\n",
      "{'loss': 0.0508, 'grad_norm': 2.1274962425231934, 'learning_rate': 5.723029839326702e-07, 'epoch': 9.73}\n",
      "{'loss': 0.0527, 'grad_norm': 1.015350341796875, 'learning_rate': 4.192807957153788e-07, 'epoch': 9.8}\n",
      "{'loss': 0.0528, 'grad_norm': 1.2331136465072632, 'learning_rate': 2.662586074980873e-07, 'epoch': 9.87}\n",
      "{'loss': 0.0512, 'grad_norm': 1.1303362846374512, 'learning_rate': 1.1323641928079573e-07, 'epoch': 9.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5a49b66bf9426499021e59abefc855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1265140324831009, 'eval_accuracy': 0.9634695382023064, 'eval_f1': 0.3760206364743733, 'eval_precision': 0.6413025386459763, 'eval_recall': 0.32601880877742945, 'eval_runtime': 3.0425, 'eval_samples_per_second': 1783.38, 'eval_steps_per_second': 111.749, 'epoch': 9.95}\n",
      "{'train_runtime': 1015.1144, 'train_samples_per_second': 427.637, 'train_steps_per_second': 13.368, 'train_loss': 0.09082458361862508, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13570, training_loss=0.09082458361862508, metrics={'train_runtime': 1015.1144, 'train_samples_per_second': 427.637, 'train_steps_per_second': 13.368, 'total_flos': 1.43909582570496e+16, 'train_loss': 0.09082458361862508, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Initialize trainer with our custom datasets\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=custom_train_dataset,\n",
    "    eval_dataset=custom_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d02a406da1b4371b232b65d73390feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.1243186742067337, 'eval_accuracy': 0.9636868567216826, 'eval_f1': 0.37498611678788357, 'eval_precision': 0.6347143582701688, 'eval_recall': 0.3220097961763312, 'eval_runtime': 3.3762, 'eval_samples_per_second': 1607.427, 'eval_steps_per_second': 100.705, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(custom_test_dataset)\n",
    "print(f\"Test results: {test_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindscribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
